{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dbe03c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "import pandas as pd\n",
    "import sklearn.decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "# import keras\n",
    "from sklearn import preprocessing,linear_model\n",
    "from sklearn.metrics import pairwise_distances,mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "sys.path.insert(0, '../utils/') \n",
    "from readProfiles import *\n",
    "from pred_models import *\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "# from utils import networksEvol, tsne, readProfiles\n",
    "import umap\n",
    "\n",
    "##### create single blue colormap to change defualt colors in yellowbrick\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "blue_cmap = cm.get_cmap('Blues', 200)\n",
    "single_blue_cmap=ListedColormap(blue_cmap(np.linspace(0.7, 0.9, 20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c14ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f065ac79",
   "metadata": {},
   "source": [
    "## Read treatment level profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34cb6562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/workspace_rosetta/workspace/software/2021_Haghighi_NeurIPS_Dataset_submitted/App1.single_feature_prediction/../utils/readProfiles.py:42: DtypeWarning: Columns (1023,1028) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  l1k_data_repLevel=pd.read_csv(dataDir+'/L1000/replicate_level_l1k.csv.gz')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUAD: Replicate Level Shapes (nSamples x nFeatures): cp:  6144 , 1569 ,  l1k:  4232 , 978\n",
      "l1k n of rep:  8.0\n",
      "cp n of rep:  8.0\n",
      "CP: from  593  to  364\n",
      "l1k: from  529  to  275\n",
      "CP and l1k high rep overlap:  197\n",
      "Treatment Level Shapes (nSamples x nFeatures+metadata): (198, 1570) (198, 979) Merged Profiles Shape: (198, 2548)\n"
     ]
    }
   ],
   "source": [
    "procProf_dir = \"/home/ubuntu/datasetsbucket/Rosetta-GE-CP/\"\n",
    "# results_dir='./results/'\n",
    "\n",
    "dataset = \"LUAD\"\n",
    "\n",
    "################################################\n",
    "pertColName = \"PERT\"\n",
    "\n",
    "mergProf_treatLevel, cp_features, l1k_features = read_paired_treatment_level_profiles(\n",
    "    procProf_dir, dataset, \"normalized\", \"highRepOverlap\", 1\n",
    ")\n",
    "\n",
    "\n",
    "l1k = mergProf_treatLevel[[pertColName] + l1k_features]\n",
    "cp = mergProf_treatLevel[[pertColName] + cp_features]\n",
    "\n",
    "scaler_ge = preprocessing.StandardScaler()\n",
    "scaler_cp = preprocessing.StandardScaler()\n",
    "l1k_scaled = l1k.copy()\n",
    "l1k_scaled[l1k_features] = scaler_ge.fit_transform(l1k[l1k_features].values)\n",
    "cp_scaled = cp.copy()\n",
    "cp_scaled[cp_features] = scaler_cp.fit_transform(\n",
    "    cp[cp_features].values.astype(\"float64\")\n",
    ")\n",
    "\n",
    "\n",
    "if 1:\n",
    "    cp = cp_scaled.copy()\n",
    "    l1k = l1k_scaled.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d34735b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7514da4b",
   "metadata": {},
   "source": [
    "## For a selected landmark gene, here how we sample images:\n",
    "- We fit a linear model to treatment level profiles\n",
    "- We filter the sample to the one that have confident predictions (sample that have l1 norm (true, pred) less than 0.3)\n",
    "- We samples select highest and lowest prediction values in this filtered set\n",
    "- We read replicate level profiles\n",
    "- We randomly select one replicate (pert replicates are at the same well of 8 different plates)\n",
    "- We select site in the middle of the well (s5 out of 9 available sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c2886a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/workspace_rosetta/workspace/software/2021_Haghighi_NeurIPS_Dataset_submitted/App1.single_feature_prediction/../utils/readProfiles.py:42: DtypeWarning: Columns (1023,1028) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  l1k_data_repLevel=pd.read_csv(dataDir+'/L1000/replicate_level_l1k.csv.gz')\n"
     ]
    }
   ],
   "source": [
    "dataset = \"LUAD\"\n",
    "profileType = \"normalized_variable_selected\"\n",
    "per_plate_normalized_flag = 1\n",
    "[cp_data_repLevel, cp_features], [\n",
    "    l1k_data_repLevel,\n",
    "    l1k_features,\n",
    "] = read_replicate_level_profiles(\n",
    "    procProf_dir, dataset, profileType, per_plate_normalized_flag\n",
    ")\n",
    "\n",
    "l1k, l1k_features_gn = rename_affyprobe_to_genename(l1k, l1k_features)\n",
    "#####################################################\n",
    "dict_imag_lookup = {}\n",
    "# luad_genes_to_inspect_ims=['PRKAG2','BNIP3L','NIPSNAP1','MYO10']\n",
    "# luad_genes_to_inspect_ims=['ETFB','CISD1','SPP1', 'CDK4', 'S100A4','TSC22D3','MRPL19','TOMM34']\n",
    "# luad_genes_to_inspect_ims=['NFKBIA','S100A4','S100A13','ETFB','CISD1']\n",
    "luad_genes_to_inspect_ims = [\"HDAC6\"]\n",
    "l1k_2 = l1k.copy()\n",
    "for g in luad_genes_to_inspect_ims:\n",
    "    model = linear_model.Lasso(alpha=0.02)\n",
    "    model.fit(cp[cp_features], l1k[g])\n",
    "    y_pred = model.predict(cp[cp_features])\n",
    "    l1k_2[\"pred\"] = y_pred\n",
    "    l1k_2[\"diff\"] = abs(l1k_2[\"pred\"] - l1k[g])\n",
    "    #     l1k_2[l1k_2['diff']<0.3]\n",
    "    pert_to_vis_max = (\n",
    "        l1k_2[l1k_2[\"diff\"] < 0.3]\n",
    "        .sort_values(by=[\"pred\"], ascending=False)[:1]\n",
    "        .PERT.values[0]\n",
    "    )\n",
    "    p, w = (\n",
    "        cp_data_repLevel[cp_data_repLevel[\"x_mutation_status\"] == pert_to_vis_max]\n",
    "        .sample(1)[[\"Metadata_Plate\", \"Metadata_Well\"]]\n",
    "        .values[0]\n",
    "    )\n",
    "    dict_imag_lookup[g] = {}\n",
    "    dict_imag_lookup[g][\"high_\" + pert_to_vis_max] = [p, w]\n",
    "    pert_to_vis_min = (\n",
    "        l1k_2[l1k_2[\"diff\"] < 0.3]\n",
    "        .sort_values(by=[\"pred\"], ascending=False)[-1:]\n",
    "        .PERT.values[0]\n",
    "    )\n",
    "    p, w = (\n",
    "        cp_data_repLevel[cp_data_repLevel[\"x_mutation_status\"] == pert_to_vis_min]\n",
    "        .sample(1)[[\"Metadata_Plate\", \"Metadata_Well\"]]\n",
    "        .values[0]\n",
    "    )\n",
    "    dict_imag_lookup[g][\"low_\" + pert_to_vis_min] = [p, w]\n",
    "#     print(g,pert_to_vis_max,pert_to_vis_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a37eddcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HDAC6': {'high_KEAP1_WT.c': [52674, 'n23'],\n",
       "  'low_NFE2L2_WT.o': [52665, 'b17']}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_imag_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446292a3",
   "metadata": {},
   "source": [
    "## Run the following on DGX where luad compressed images currently reside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b891093",
   "metadata": {},
   "outputs": [],
   "source": [
    "where2move = \"/dgx1nas1/storage/data/marziehhaghighi/rosetta_luad_ims/\"\n",
    "luad_im_add = (\n",
    "    \"/dgx1nas1/storage/data/jarevalo/luad/dp_project/outputs/compressed/images/\"\n",
    ")\n",
    "for g in dict_imag_lookup:\n",
    "    print(dict_imag_lookup[g])\n",
    "    geneName = g\n",
    "    os.system(\"mkdir \" + where2move + g)\n",
    "    perts_dict = dict_imag_lookup[g].keys()\n",
    "    for pe in perts_dict:\n",
    "        os.system(\"mkdir \" + where2move + g + \"/\" + pe)\n",
    "        p, w = dict_imag_lookup[g][pe]\n",
    "        print(p, w)\n",
    "        plate_path = luad_im_add + str(p)\n",
    "        list_plate_ims = os.listdir(plate_path)\n",
    "        random_ims = [l for l in list_plate_ims if (\"_\" + w + \"_\" in l) and (\"s5\" in l)]\n",
    "        print(random_ims)\n",
    "        #         fgsdfsfd\n",
    "        #         random_im=random.choice(random_ims)\n",
    "        for r in random_ims:\n",
    "            command = (\n",
    "                'cp \"' + plate_path + \"/\" + r + '\" \"' + where2move + g + \"/\" + pe + '/\"'\n",
    "            )\n",
    "            os.system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe649e7",
   "metadata": {},
   "source": [
    "## Check feature importance for a landmark gene of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2228aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "ge_features_under_test = [\"CISD1\"]\n",
    "\n",
    "l1k, l1k_features_gn = rename_affyprobe_to_genename(l1k, l1k_features)\n",
    "\n",
    "for g in ge_features_under_test:\n",
    "    #     viz = FeatureImportances(linear_model.Lasso(),relative=True, topn=20)\n",
    "    #     viz = FeatureImportances(linear_model.Lasso(alpha=0.001), labels=l1k_features_gn, relative=False,topn=20)\n",
    "    print(g)\n",
    "    #     model = linear_model.LinearRegression()\n",
    "    model = linear_model.Lasso(alpha=0.02)\n",
    "    model.fit(cp[cp_features], l1k[g])\n",
    "    # #     model = RandomForestClassifier(n_estimators=10),colormap=single_blue_cmap\n",
    "    #     viz = FeatureImportances(model,topn=20,colormap='coolwarm')\n",
    "    viz = FeatureImportances(model, topn=20, colormap=single_blue_cmap)\n",
    "\n",
    "    viz.fit(cp[cp_features], l1k[g])\n",
    "    viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c008df",
   "metadata": {},
   "source": [
    "## For the selected list that are in a cluster in figure2d generate images in appendix J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d72282",
   "metadata": {},
   "source": [
    "Anne's note:\n",
    "For the following genes \n",
    "\n",
    "I recommend four columns of images where you have the two headings: \n",
    "\"High levels of gene's mRNA\" and \n",
    "\"Low levels of gene's mRNA\" and \n",
    "within each you have two columns of images: DNA + RNA (which is w1 and w3). \n",
    "Then you have five rows of images for the 6 genes mentioned in the cluster. \n",
    "You will want to label each pair of RNA/DNA images with the name of the perturbation. \n",
    "You will also want to mention in the legend how you chose those perturbations \n",
    "(was it based on measured levels of mRNA or predicted?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c13c933",
   "metadata": {},
   "source": [
    "##### Run the following cell on DGX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890954ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cluster = [\"SPP1\", \"CDK4\", \"S100A4\", \"BNIP3L\", \"HDAC6\", \"S100A13\"]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "dict_imag_lookup = {\n",
    "    \"SPP1\": {\"high_NFE2L2_p.T80K\": [52651, \"j02\"], \"low_KEAP1_p.E611D\": [52664, \"g10\"]},\n",
    "    \"CDK4\": {\"high_KRAS_p.G13V\": [52665, \"p14\"], \"low_RAF1_p.S259F\": [52654, \"j08\"]},\n",
    "    \"S100A4\": {\"high_RARA_p.M284I\": [52657, \"k14\"], \"low_NRAS_p.Q61L\": [52657, \"i23\"]},\n",
    "    \"BNIP3L\": {\"high_NFE2L2_WT.o\": [52671, \"b08\"], \"low_BRAF_p.V600E\": [52674, \"i23\"]},\n",
    "    \"HDAC6\": {\"high_KEAP1_WT.c\": [52674, \"n23\"], \"low_NFE2L2_WT.o\": [52665, \"b17\"]},\n",
    "    \"S100A13\": {\"high_BRAF_p.V600E\": [52666, \"i23\"], \"low_CASP8_WT.o\": [52662, \"p19\"]},\n",
    "}\n",
    "\n",
    "where2move = \"/dgx1nas1/storage/data/marziehhaghighi/rosetta_luad_ims/\"\n",
    "luad_im_add = (\n",
    "    \"/dgx1nas1/storage/data/jarevalo/luad/dp_project/outputs/compressed/images/\"\n",
    ")\n",
    "\n",
    "import skimage.io\n",
    "\n",
    "f, axarr = plt.subplots(len(dict_imag_lookup), 4, figsize=(15, 15))\n",
    "f.subplots_adjust(hspace=0.04, wspace=0)\n",
    "gi = 0\n",
    "for g in dict_imag_lookup:\n",
    "    #     print(dict_imag_lookup[g])\n",
    "    #     geneName=g\n",
    "    perts_dict = dict_imag_lookup[g].keys()\n",
    "    pei = 0\n",
    "    for pe in perts_dict:\n",
    "        p, w = dict_imag_lookup[g][pe]\n",
    "        #         print(p,w)\n",
    "        plate_path = luad_im_add + str(p)\n",
    "        list_plate_ims = os.listdir(plate_path)\n",
    "        random_ims = [l for l in list_plate_ims if (\"_\" + w + \"_\" in l) and (\"s5\" in l)]\n",
    "        random_ims_dna = [l for l in random_ims if (\"w1\" in l)]\n",
    "        random_ims_rna = [l for l in random_ims if (\"w3\" in l)]\n",
    "        random_ims_dna_rna = random_ims_dna + random_ims_rna\n",
    "        #         print(random_ims_dna_rna)\n",
    "        ri = 0\n",
    "        for r in random_ims_dna_rna:\n",
    "            imD0 = skimage.io.imread(plate_path + \"/\" + r)\n",
    "            imD2 = imD0[270:810, 270:810]\n",
    "\n",
    "            backtorgb = cv2.cvtColor(imD2, cv2.COLOR_GRAY2RGB)\n",
    "            if ri == 0:\n",
    "                axarr[0, pei].set_title(\"DNA\", fontsize=12)\n",
    "                backtorgb[:, :, 0] = 0.5 * backtorgb[:, :, 0]\n",
    "            else:\n",
    "                axarr[0, pei].set_title(\"RNA\", fontsize=12)\n",
    "                backtorgb[:, :, 2] = 0.5 * backtorgb[:, :, 2]\n",
    "\n",
    "            #             R = np.stack((np.zeros(imD2.shape),imD2, imD2), axis=2)\n",
    "            axarr[gi, pei].imshow(backtorgb)\n",
    "            # axarr[0,cpi].set_title(c,fontsize=18);\n",
    "            axarr[gi, pei].xaxis.set_major_locator(plt.NullLocator())\n",
    "            axarr[gi, pei].yaxis.set_major_locator(plt.NullLocator())\n",
    "\n",
    "            ri += 1\n",
    "            pei += 1\n",
    "\n",
    "        axarr[gi, pei - 2].set_ylabel(\"_\".join(pe.split(\"_\")[1:]), fontsize=12)\n",
    "    #     axarr[gi,0].set_ylabel(g,fontsize=18);\n",
    "    axarr[gi, 0].set_ylabel(g + \"\\n\" + axarr[gi, 0].get_ylabel())\n",
    "    gi += 1\n",
    "\n",
    "# plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
