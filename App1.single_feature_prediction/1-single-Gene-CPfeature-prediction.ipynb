{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "import pandas as pd\n",
    "import sklearn.decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "# import keras\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import pairwise_distances,mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from utils.readProfiles import *\n",
    "from utils.pred_models import *\n",
    "from utils.saveAsNewSheetToExistingFile import saveAsNewSheetToExistingFile\n",
    "from multiprocessing import Pool\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "# from utils import networksEvol, tsne, readProfiles\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "\n",
    "\n",
    "- CDRP-BBBC047-Bray-CP-GE (Cell line: U2OS):\n",
    "    * There are 30,430 and 21,782 unique compounds for CP and GE datasets, respectively.\n",
    "    * Median number of replicates for each dataset is as follows: CP: ~4 , GE: ~3. \n",
    "    * 20,358 compounds are present in both datasets.\n",
    "    * Replicate Level Shapes (nSamples x nFeatures): cp:  (153386 , 1783) ,  ge:  (68120 , 977)\n",
    "    * Treatment Level Shapes (nSamples x nFeatures): cp:  (30430, 1786)   ,  ge:  (21782, 981) \n",
    "    * Merged Profiles Shape:                              (20358, 2766)\n",
    "    * High Rep corr: CP: 30618 to 7892, l1k: 21069 to 2870, overlap:  3\n",
    "    \n",
    "    \n",
    "- CDRPBIO-BBBC036-Bray-CP-GE (Cell line: U2OS):\n",
    "    * There are 30,430 and 21,782 unique compounds for CP and GE datasets, respectively.\n",
    "    * Median number of replicates for each dataset is as follows: CP: ~4 , GE: ~3. \n",
    "    * 20,358 compounds are present in both datasets.\n",
    "    * Replicate Level Shapes (nSamples x nFeatures): cp:  (153386 , 1783) ,  ge:  (68120 , 977)\n",
    "    * Treatment Level Shapes (nSamples x nFeatures): cp:  (30430, 1786)   ,  ge:  (21782, 981) \n",
    "    * Merged Profiles Shape:                   \n",
    "    * High Rep corr: CP: 2239 to 312, l1k: 1535 to 448, overlap:  131\n",
    "\n",
    "\n",
    "- LUAD-BBBC041-Caicedo-CP-GE (Cell line: A549) : \n",
    "    * There are 593 and 529 unique alleles for CP and GE datasets, respectively.\n",
    "    * Median number of replicates for each dataset is as follows: CP: ~8, GE: ~8.\n",
    "    * 525 alleles are present in both datasets.\n",
    "    * Replicate Level Shapes (nSamples x nFeatures): cp:  (6144 , 1783) ,  ge:  (4232 , 978)\n",
    "    * Treatment Level Shapes (nSamples x nFeatures): cp: (593, 1786) , ge: (529, 979) \n",
    "    * Merged Profiles Shape:                             (525, 2764)    \n",
    "    * High Rep corr: CP: x to x, l1k: x to x, overlap:  x    \n",
    "    \n",
    "    \n",
    "- TA-ORF-BBBC037-Rohban-CP-GE (Cell line: U2OS) :\n",
    "    * There are 299 and 226 number of unique compounds for CP and GE datasets respectively.\n",
    "    * Median number of replicates for each dataset is as follows: CP: ~5 , GE: ~2.\n",
    "    * 188 alleles are present in both datasets.\n",
    "    * Replicate Level Shapes (nSamples x nFeatures):         cp: (1920 , 1783) ,  ge: (729 , 978)\n",
    "    * Treatment Level Shapes (nSamples x nFeatures+metadata):cp: (323, 1784)   ,  ge: (328, 979)\n",
    "    * Merged Profiles Shape:                                     (149, 2762)\n",
    "    * High Rep corr: CP: x to x, l1k: x to x, overlap:  x    \n",
    "    \n",
    "    \n",
    "- LINCS-Pilot1-CP-GE (Cell line: A549) :\n",
    "    * There are 1570 unique compounds across 7 doses for CP dataset\n",
    "    * There are x unique compounds across 7 doses for GE dataset\n",
    "    * Median number of replicates for each dataset is as follows: CP: ~5 , GE: ~3.\n",
    "    * 6984 \"compounds-dose\" are present in both datasets. \n",
    "    * Replicate Level Shapes (nSamples x nFeatures):         cp: (52223 , 1747) ,  ge: (27837 , 978)\n",
    "    * Treatment Level Shapes (nSamples x nFeatures+metadata):cp: (9394, 1748)   ,  ge: (8370, 979)\n",
    "    * Merged Profiles Shape:                                     (6984, 2726)\n",
    "    * High Rep corr: CP: 9394 to 4647, l1k: 8369  to  2338, overlap:  1140\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "procProf_dir='/home/ubuntu/datasetsbucket/Rosetta-GE-CP/'\n",
    "# procProf_dir='/home/ubuntu/bucket/projects/2018_04_20_Rosetta/workspace/'\n",
    "metadata_dir='/home/ubuntu/bucket/projects/2018_04_20_Rosetta/workspace/metadata/'\n",
    "results_dir='./results/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of single GE expression levels based on the full CP profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################################################\n",
    "# dataset options: 'CDRP' , 'LUAD', 'TAORF', 'LINCS', 'CDRP-bio'\n",
    "datasets=['LUAD'];\n",
    "# datasets=['LINCS', 'CDRP-bio','CDRP'];\n",
    "# datasets=['TAORF','LUAD','LINCS', 'CDRP-bio']\n",
    "\n",
    "DT_kfold={'LUAD':10, 'TAORF':5, 'LINCS':25, 'CDRP-bio':6,'CDRP':40}\n",
    "\n",
    "################################################\n",
    "# CP Profile Type options: 'augmented' , 'normalized', 'normalized_variable_selected'\n",
    "profileType='normalized_variable_selected'\n",
    "\n",
    "################################################\n",
    "# filtering to compounds which have high replicates for both GE and CP datasets\n",
    "# highRepOverlapEnabled=0\n",
    "# 'highRepUnion','highRepOverlap'\n",
    "filter_perts='highRepOverlap'\n",
    "\n",
    "################################################\n",
    "pertColName='PERT'\n",
    "\n",
    "\n",
    "if filter_perts:\n",
    "    f='filt'\n",
    "else:\n",
    "    f=''\n",
    "    \n",
    "# def f(dataset):\n",
    "for dataset in datasets:\n",
    "   \n",
    "\n",
    "    mergProf_treatLevel,cp_features,l1k_features = \\\n",
    "    read_paired_treatment_level_profiles(procProf_dir,dataset,profileType,filter_perts,1)\n",
    "\n",
    "    l1k=mergProf_treatLevel[[pertColName]+l1k_features]\n",
    "    cp=mergProf_treatLevel[[pertColName]+cp_features]\n",
    "\n",
    "\n",
    "    if dataset=='LINCS':     \n",
    "        cp['Compounds']=cp['PERT'].str[0:13]\n",
    "        l1k['Compounds']=l1k['PERT'].str[0:13]\n",
    "    else:\n",
    "        cp['Compounds']=cp['PERT']\n",
    "        l1k['Compounds']=l1k['PERT']      \n",
    "\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    group_labels=le.fit_transform(l1k['Compounds'].values)\n",
    "\n",
    "\n",
    "    scaler_ge = preprocessing.StandardScaler()\n",
    "    scaler_cp = preprocessing.StandardScaler()\n",
    "    l1k_scaled=l1k.copy()\n",
    "    l1k_scaled[l1k_features] = scaler_ge.fit_transform(l1k[l1k_features].values)\n",
    "    cp_scaled=cp.copy()\n",
    "    cp_scaled[cp_features] = scaler_cp.fit_transform(cp[cp_features].values.astype('float64'))\n",
    "    \n",
    "    \n",
    "    for model in [\"Lasso\"]:#[\"Lasso\",\"MLP\",\"RFR\"]:    \n",
    "\n",
    "        if 1:\n",
    "            cp=cp_scaled.copy()\n",
    "            l1k=l1k_scaled.copy()\n",
    "\n",
    "        ##############################\n",
    "         \n",
    "        k_fold=DT_kfold[dataset]\n",
    "            \n",
    "        pred_df=pd.DataFrame(index=range(k_fold),columns=l1k_features)\n",
    "        pred_df_rand=pd.DataFrame(index=range(k_fold),columns=l1k_features)\n",
    "        ii=0\n",
    "        for l in l1k_features:\n",
    "            ii+=1\n",
    "            print(ii)\n",
    "            if model==\"Lasso\":\n",
    "                scores,scores_rand=lasso_cv_plus_model_selection(cp[cp_features],l1k[l],k_fold,group_labels,1)  \n",
    "#                 sfaadadd\n",
    "#                 scores,scores_rand=lasso_cv(cp[cp_features],l1k[l],k_fold,group_labels)\n",
    "            elif model==\"MLP\":\n",
    "                scores,scores_rand=MLP_cv_plus_model_selection(cp[cp_features],l1k[l],k_fold,group_labels,1)\n",
    "#                 scores,scores_rand=MLP_cv(cp[cp_features],l1k[l],k_fold,group_labels)  \n",
    "            elif model==\"Ridge\":\n",
    "                scores,scores_rand=ridge_cv_plus_model_selection(cp[cp_features],l1k[l],k_fold,group_labels,1)\n",
    "#                 gafgfdssgfd\n",
    "#                 scores,scores_rand=MLP_cv(cp[cp_features],l1k[l],k_fold,group_labels)  \n",
    "            elif model==\"RFR\":\n",
    "                scores,scores_rand=RFR_cv_plus_model_selection(cp[cp_features],l1k[l],k_fold,group_labels,1)  \n",
    "            \n",
    "            pred_df[l]=scores\n",
    "            pred_df_rand[l]=scores_rand\n",
    "\n",
    "            \n",
    "        ########################### mapping prob_ids to genes names    \n",
    "        pred_df,_=rename_affyprobe_to_genename(pred_df,l1k_features)\n",
    "        pred_df_rand,_=rename_affyprobe_to_genename(pred_df_rand,l1k_features)\n",
    "        \n",
    "\n",
    "\n",
    "        meltedPredDF=pd.melt(pred_df).rename(columns={'variable':'lmGens','value':'pred score'})\n",
    "        meltedPredDF_rand=pd.melt(pred_df_rand).rename(columns={'variable':'lmGens','value':'pred score'})\n",
    "        meltedPredDF['d']=\"n-folds\"\n",
    "        meltedPredDF_rand['d']=\"random\"\n",
    "        filename=results_dir+'/SingleGenePred/scores.xlsx'\n",
    "        \n",
    "        profTypeAbbrev=''.join([s[0] for s in profileType.split('_')])\n",
    "        \n",
    "#         saveAsNewSheetToExistingFile(filename,pd.concat([meltedPredDF,meltedPredDF_rand],ignore_index=True),\\\n",
    "#                                      model+'-'+dataset+'-'+profTypeAbbrev+'-'+f+'-'+str(k_fold)+'-ht')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1k_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of single CP features based on the full GE profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################################################\n",
    "# dataset options: 'CDRP' , 'LUAD', 'TAORF', 'LINCS', 'CDRP-bio'\n",
    "datasets=['LINCS', 'CDRP-bio'];\n",
    "# datasets=['TAORF','CDRP'];\n",
    "\n",
    "DT_kfold={'LUAD':10, 'TAORF':10, 'LINCS':20, 'CDRP-bio':10,'CDRP':40}\n",
    "\n",
    "# DT_kfold={'LUAD':9, 'TAORF':5, 'LINCS':25, 'CDRP-bio':6,'CDRP':40}\n",
    "\n",
    "\n",
    "################################################\n",
    "# CP Profile Type options: 'augmented' , 'normalized', 'normalized_variable_selected'\n",
    "# 'normalized_feature_select_dmso'\n",
    "profileType='normalized'\n",
    "\n",
    "################################################\n",
    "# filtering to compounds which have high replicates for both GE and CP datasets\n",
    "# highRepOverlapEnabled=0\n",
    "# 'highRepUnion','highRepOverlap'\n",
    "filter_perts='highRepOverlap'\n",
    "\n",
    "\n",
    "################################################\n",
    "pertColName='PERT'\n",
    "\n",
    "if filter_perts:\n",
    "    f='filt'\n",
    "else:\n",
    "    f=''\n",
    "    \n",
    "# def f(dataset):\n",
    "for dataset in datasets:\n",
    "            \n",
    "    mergProf_treatLevel,cp_features,l1k_features = \\\n",
    "    read_paired_treatment_level_profiles(procProf_dir,dataset,profileType,filter_perts,1)\n",
    "\n",
    "    l1k=mergProf_treatLevel[[pertColName]+l1k_features]\n",
    "    cp=mergProf_treatLevel[[pertColName]+cp_features]\n",
    "\n",
    "        \n",
    "    if dataset=='LINCS':     \n",
    "        cp['Compounds']=cp['PERT'].str[0:13]\n",
    "        l1k['Compounds']=l1k['PERT'].str[0:13]\n",
    "    else:\n",
    "        cp['Compounds']=cp['PERT']\n",
    "        l1k['Compounds']=l1k['PERT']      \n",
    "\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    group_labels=le.fit_transform(l1k['Compounds'].values)        \n",
    "        \n",
    "\n",
    "    scaler_ge = preprocessing.StandardScaler()\n",
    "    scaler_cp = preprocessing.StandardScaler()\n",
    "    l1k_scaled=l1k.copy()\n",
    "    l1k_scaled[l1k_features] = scaler_ge.fit_transform(l1k[l1k_features].values)\n",
    "    cp_scaled=cp.copy()\n",
    "    cp_scaled[cp_features] = scaler_cp.fit_transform(cp[cp_features].values.astype('float64'))\n",
    "\n",
    "    for model in [\"Lasso\", \"MLP\"]:    \n",
    "    \n",
    "#         if model==\"MLP\":\n",
    "#             cp_scaled[cp_features] =preprocessing.MinMaxScaler(feature_range=(-1, 1)).fit_transform(cp_scaled[cp_features].values)   \n",
    "#             cp_scaled[l1k_features] =preprocessing.MinMaxScaler(feature_range=(-1, 1)).fit_transform(cp_scaled[l1k_features].values)           \n",
    "\n",
    "        if 1:\n",
    "            cp=cp_scaled.copy()\n",
    "            l1k=l1k_scaled.copy()\n",
    "\n",
    "        ##############################\n",
    "            \n",
    "            \n",
    "        k_fold=DT_kfold[dataset]\n",
    "#         k_fold=int(np.unique(group_labels).shape[0]/20)            \n",
    "        pred_df=pd.DataFrame(index=range(k_fold),columns=cp_features)\n",
    "        pred_df_rand=pd.DataFrame(index=range(k_fold),columns=cp_features)\n",
    "        ii=0\n",
    "        for c in cp_features:\n",
    "            ii+=1\n",
    "            print(ii)            \n",
    "            if model==\"Lasso\":\n",
    "                scores,scores_rand=lasso_cv_plus_model_selection(l1k[l1k_features],cp[c],k_fold,group_labels,1)\n",
    "            elif model==\"MLP\":\n",
    "                scores,scores_rand=MLP_cv_plus_model_selection(l1k[l1k_features],cp[c],k_fold,group_labels,1)\n",
    "            pred_df[c]=scores\n",
    "            pred_df_rand[c]=scores_rand\n",
    "\n",
    "            \n",
    "        meltedPredDF=pd.melt(pred_df).rename(columns={'variable':'CP-Features','value':'pred score'})\n",
    "        meltedPredDF_rand=pd.melt(pred_df_rand).rename(columns={'variable':'CP-Features','value':'pred score'})\n",
    "        meltedPredDF['d']=\"n-folds\"\n",
    "        meltedPredDF_rand['d']=\"random\"\n",
    "#         filename='../../results/SingleCPfeatPred/scores.xlsx'\n",
    "        filename=results_dir+'/SingleCPfeatPred/scores.xlsx'\n",
    "        \n",
    "        profTypeAbbrev=''.join([s[0] for s in profileType.split('_')])        \n",
    "        \n",
    "        saveAsNewSheetToExistingFile(filename,pd.concat([meltedPredDF,meltedPredDF_rand],ignore_index=True),\\\n",
    "                                     model+'-'+dataset+'-'+profTypeAbbrev+'-'+f+'-'+str(k_fold)+'-ht')\n",
    "\n",
    "\n",
    "    \n",
    "#     return \n",
    "\n",
    "# with Pool(10) as p:\n",
    "#     p.map(f, datasets)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CP Category specific scores for single gene prediction - based on Lasso  regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "# simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "# from sklearn.exceptions import ConvergenceWarning\n",
    "ConvergenceWarning('ignore')\n",
    "\n",
    "################################################\n",
    "# dataset options: 'CDRP' , 'LUAD', 'TAORF', 'LINCS', 'CDRP-bio'\n",
    "# datasets=['LUAD', 'TAORF', 'LINCS', 'CDRP-bio'];\n",
    "datasets=['LUAD'];\n",
    "\n",
    "# DT_kfold={'LUAD':10, 'TAORF':5, 'LINCS':20, 'CDRP-bio':20,'CDRP':40}\n",
    "\n",
    "DT_kfold={'LUAD':9, 'TAORF':5, 'LINCS':25, 'CDRP-bio':6,'CDRP':40}\n",
    "\n",
    "\n",
    "################################################\n",
    "# CP Profile Type options: 'augmented' , 'normalized', 'normalized_variable_selected'\n",
    "# 'normalized_feature_select_dmso'\n",
    "profileType='normalized'\n",
    "\n",
    "################################################\n",
    "# filtering to compounds which have high replicates for both GE and CP datasets\n",
    "# highRepOverlapEnabled=0\n",
    "# 'highRepUnion','highRepOverlap'\n",
    "filter_perts='highRepOverlap'\n",
    "\n",
    "\n",
    "################################################\n",
    "pertColName='PERT'\n",
    "profileLevel='treatment'; #'replicate'  or  'treatment'\n",
    "if filter_perts:\n",
    "    f='filt'\n",
    "else:\n",
    "    f=''\n",
    "    \n",
    "# def f(dataset):\n",
    "for dataset in datasets:\n",
    "        \n",
    "    \n",
    "    mergProf_treatLevel,cp_features,l1k_features = \\\n",
    "    read_paired_treatment_level_profiles(procProf_dir,dataset,profileType,filter_perts,1)\n",
    "\n",
    "\n",
    "    l1k=mergProf_treatLevel[[pertColName]+l1k_features]\n",
    "    cp=mergProf_treatLevel[[pertColName]+cp_features]\n",
    "\n",
    "        \n",
    "    if dataset=='LINCS':     \n",
    "        cp['Compounds']=cp['PERT'].str[0:13]\n",
    "        l1k['Compounds']=l1k['PERT'].str[0:13]\n",
    "    else:\n",
    "        cp['Compounds']=cp['PERT']\n",
    "        l1k['Compounds']=l1k['PERT']      \n",
    "\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    group_labels=le.fit_transform(l1k['Compounds'].values)        \n",
    "        \n",
    "\n",
    "    scaler_ge = preprocessing.StandardScaler()\n",
    "    scaler_cp = preprocessing.StandardScaler()\n",
    "    l1k_scaled=l1k.copy()\n",
    "    l1k_scaled[l1k_features] = scaler_ge.fit_transform(l1k[l1k_features].values)\n",
    "    cp_scaled=cp.copy()\n",
    "    cp_scaled[cp_features] = scaler_cp.fit_transform(cp[cp_features].values.astype('float64'))\n",
    "\n",
    "    if 1:\n",
    "        cp=cp_scaled.copy()\n",
    "        l1k=l1k_scaled.copy()\n",
    "\n",
    "    ##############################\n",
    "\n",
    "    # k_fold=10\n",
    "    k_fold=DT_kfold[dataset]\n",
    "    Channelss=['DNA','RNA','AGP','Mito','ER']\n",
    "    featureGroups=['Texture','Intensity','RadialDistribution']\n",
    "    relationMat_mpCat=pd.DataFrame(index=l1k_features)\n",
    "    for ch in range(len(Channelss)):\n",
    "        for f in range(len(featureGroups)):\n",
    "            print(ch,f)\n",
    "            selectedCols=cp.columns[cp.columns.str.contains(Channelss[ch]) &\\\n",
    "                           cp.columns.str.contains(featureGroups[f]) &\\\n",
    "                           cp.columns.str.contains(\"Cells_|Cytoplasm_|Nuclei_\")].tolist();\n",
    "            if selectedCols!=[]:\n",
    "                for l in l1k_features:\n",
    "#                     scores,scores_rand=lasso_cv_plus_model_selection(cp[selectedCols],l1k[l],k_fold,group_labels,0)\n",
    "                    scores,scores_rand=MLP_cv_plus_model_selection(cp[selectedCols],l1k[l],k_fold,group_labels,0)\n",
    "\n",
    "                    relationMat_mpCat.loc[l,Channelss[ch]+'_'+featureGroups[f]]=np.median(scores)\n",
    "\n",
    "    Channelss=['Nuclei','Cytoplasm','Cells']\n",
    "    featureGroups=['AreaShape']\n",
    "\n",
    "    for ch in range(len(Channelss)):\n",
    "        for f in range(len(featureGroups)):    \n",
    "            selectedCols=cp.columns[cp.columns.str.contains(Channelss[ch]) &\\\n",
    "                           cp.columns.str.contains(featureGroups[f]) &\\\n",
    "                           cp.columns.str.contains(\"Cells_|Cytoplasm_|Nuclei_\")].tolist();\n",
    "            if selectedCols!=[]:\n",
    "                for l in l1k_features:\n",
    "#                     scores,scores_rand=lasso_cv_plus_model_selection(cp[selectedCols],l1k[l],k_fold,group_labels,0)\n",
    "                    scores,scores_rand=MLP_cv_plus_model_selection(cp[selectedCols],l1k[l],k_fold,group_labels,0)\n",
    "                    \n",
    "                    relationMat_mpCat.loc[l,Channelss[ch]+'_'+featureGroups[f]]=np.median(scores)\n",
    "\n",
    "    ########################### mapping prob_ids to genes names    \n",
    "    meta=pd.read_csv(\"/home/ubuntu/bucket/projects/2018_04_20_Rosetta/workspace/metadata/affy_probe_gene_mapping.txt\",delimiter=\"\\t\",header=None, names=[\"probe_id\", \"gene\"])\n",
    "    meta_gene_probID=meta.set_index('probe_id')\n",
    "    d = dict(zip(meta_gene_probID.index, meta_gene_probID['gene']))\n",
    "    relationMat_mpCat = relationMat_mpCat.rename(index=d)    \n",
    "\n",
    "\n",
    "    filename=results_dir+'/SingleGenePred_cpCategoryMap/cat_scores_maps.xlsx'\n",
    "\n",
    "    profTypeAbbrev=''.join([s[0] for s in profileType.split('_')])        \n",
    "\n",
    "    saveAsNewSheetToExistingFile(filename,relationMat_mpCat,dataset+'-'+str(k_fold)+'-MLP-ht')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp.columns[cp.columns.str.contains('RadialDistribution')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topGenes_mito_radial.sort_values(by='Mito_RadialDistribution').index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave dataset out Cross validation - on LUAD and LINCS (2-folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11179/3095622044.py:26: DtypeWarning: Columns (18,19,1820,1821) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  readMergedProfiles(procProf_dir,'LINCS',profileType,profileLevel,nRep,filter_perts);\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINCS: Replicate Level Shapes (nSamples x nFeatures): cp:  52223 , 1670 ,  l1k:  27837 , 978\n",
      "l1k n of rep:  3.0\n",
      "cp n of rep:  5.0\n",
      "CP: from  9394  to  4647\n",
      "l1k: from  8369  to  2338\n",
      "CP and l1k high rep overlap:  1140\n",
      "Treatment Level Shapes (nSamples x nFeatures+metadata): (1141, 1673) (1141, 980) Merged Profiles Shape: (1141, 2652)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11179/3095622044.py:29: DtypeWarning: Columns (1023,1028) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  readMergedProfiles(procProf_dir,'LUAD',profileType,profileLevel,nRep,filter_perts);\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUAD: Replicate Level Shapes (nSamples x nFeatures): cp:  6144 , 1569 ,  l1k:  4232 , 978\n",
      "l1k n of rep:  8.0\n",
      "cp n of rep:  8.0\n",
      "CP: from  593  to  364\n",
      "l1k: from  529  to  275\n",
      "CP and l1k high rep overlap:  197\n",
      "Treatment Level Shapes (nSamples x nFeatures+metadata): (198, 1572) (198, 979) Merged Profiles Shape: (198, 2550)\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "# dataset options: 'CDRP' , 'LUAD', 'TAORF', 'LINCS', 'CDRP-bio'\n",
    "datasets=['LUAD','LINCS'];\n",
    "# datasets=['LINCS', 'CDRP-bio','CDRP'];\n",
    "\n",
    "################################################\n",
    "# CP Profile Type options: 'augmented' , 'normalized', 'normalized_variable_selected'\n",
    "profileType='normalized'\n",
    "\n",
    "################################################\n",
    "# filtering to compounds which have high replicates for both GE and CP datasets\n",
    "# highRepOverlapEnabled=0\n",
    "# 'highRepUnion','highRepOverlap'\n",
    "filter_perts='highRepOverlap'\n",
    "\n",
    "################################################\n",
    "pertColName='PERT'\n",
    "profileLevel='treatment'; #'replicate'  or  'treatment'\n",
    "if filter_perts:\n",
    "    f='filt'\n",
    "else:\n",
    "    f=''\n",
    "    \n",
    "\n",
    "mergProf_treatLevel_LI,cp_features_LI,l1k_features_LI= \\\n",
    "read_paired_treatment_level_profiles(procProf_dir,'LINCS',profileType,filter_perts,1)\n",
    "\n",
    "mergProf_treatLevel_LU,cp_features_LU,l1k_features_LU = \\\n",
    "read_paired_treatment_level_profiles(procProf_dir,'LUAD',profileType,filter_perts,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291 119 43\n",
      "978 978 978\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(cp_features_LU),len(cp_features_LI),len(set(cp_features_LU) & set(cp_features_LI)))\n",
    "print(len(l1k_features_LU),len(l1k_features_LI),len(set(l1k_features_LU) & set(l1k_features_LI)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_features_unionFs=list(set(cp_features_LU).union(set(cp_features_LI)))\n",
    "l1k_features_unionFs=list(set(l1k_features_LU).union(set(l1k_features_LI)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1928"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cp_features_unionFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_features_allOverlappingFs=list(set(cp_features_LU) & set(cp_features_LI) & set(cp_features_unionFs))\n",
    "l1k_features_allOverlappingFs=list(set(l1k_features_LU) & set(l1k_features_LI)& set(l1k_features_unionFs))\n",
    "\n",
    "len(cp_features_allOverlappingFs)\n",
    "# cp_features_LU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# cp_features=list(set(cp_features_LU) & set(cp_features_LI))\n",
    "# l1k_features=list(set(l1k_features_LU) & set(l1k_features_LI))\n",
    "# profileType='normalized'\n",
    "\n",
    "cp_features=list(set(cp_features_LU) & set(cp_features_LI) & set(cp_features_unionFs))\n",
    "l1k_features=list(set(l1k_features_LU) & set(l1k_features_LI)& set(l1k_features_unionFs))\n",
    "profileType='normalized_variable_selected_union'\n",
    "\n",
    "\n",
    "####################\n",
    "l1k_LU=mergProf_treatLevel_LU[[pertColName]+l1k_features]\n",
    "cp_LU=mergProf_treatLevel_LU[[pertColName]+cp_features]\n",
    "\n",
    "l1k_LI=mergProf_treatLevel_LI[[pertColName]+l1k_features]\n",
    "cp_LI=mergProf_treatLevel_LI[[pertColName]+cp_features]\n",
    "\n",
    "####################\n",
    "\n",
    "\n",
    "l1k_scaled_LU=l1k_LU.copy();l1k_scaled_LI=l1k_LI.copy()\n",
    "l1k_scaled_LU[l1k_features] = preprocessing.StandardScaler().fit_transform(l1k_LU[l1k_features].values)\n",
    "l1k_scaled_LI[l1k_features] = preprocessing.StandardScaler().fit_transform(l1k_LI[l1k_features].values)\n",
    "\n",
    "cp_scaled_LU=cp_LU.copy();cp_scaled_LI=cp_LI.copy()\n",
    "cp_scaled_LU[cp_features] = preprocessing.StandardScaler().fit_transform(cp_LU[cp_features].values.astype('float64'))\n",
    "cp_scaled_LI[cp_features] = preprocessing.StandardScaler().fit_transform(cp_LI[cp_features].values.astype('float64'))\n",
    "\n",
    "fold1=[[cp_scaled_LU,l1k_scaled_LU],[cp_scaled_LI,l1k_scaled_LI]]\n",
    "fold2=[[cp_scaled_LI,l1k_scaled_LI],[cp_scaled_LU,l1k_scaled_LU]]\n",
    "\n",
    "\n",
    "pred_df=pd.DataFrame(index=range(2),columns=l1k_features)\n",
    "pred_df_rand=pd.DataFrame(index=range(2),columns=l1k_features)\n",
    "\n",
    "# for dt in [fold1,fold2]:\n",
    "for n,dt in zip([0,1],[fold1,fold2]):\n",
    "    \n",
    "    for model in [\"Ridge\"]:#[\"Lasso\",\"MLP\",\"Ridge\"]:    \n",
    "\n",
    "        ##############################\n",
    "        ii=0\n",
    "        for l in l1k_features:\n",
    "            ii+=1\n",
    "            print(ii)\n",
    "\n",
    "            X_train, X_test = dt[0][0][cp_features].values, dt[1][0][cp_features].values\n",
    "            y_train, y_test = dt[0][1][l].values, dt[1][1][l]#.values\n",
    "\n",
    "            if model==\"Lasso\":\n",
    "    #             scores,scores_rand=lasso_cv_plus_model_selection(cp[cp_features],l1k[l],k_fold,group_labels)        \n",
    "    # #                 scores,scores_rand=lasso_cv(cp[cp_features],l1k[l],k_fold,group_labels)\n",
    "                alphas1 = np.linspace(0, 0.2, 20)\n",
    "                alphas2 = np.linspace(0.2, 0.5, 10)[1:]\n",
    "                alphas=np.concatenate((alphas1,alphas2))\n",
    "            #     alphas = np.logspace(-4, -0.5, 30)\n",
    "                lasso_cv = linear_model.LassoCV(alphas=alphas, random_state=0, max_iter=1000,selection='random')\n",
    "\n",
    "                lasso_cv.fit(X_train, y_train)  \n",
    "                r2_score=lasso_cv.score(X_test, y_test.values) \n",
    "                r2_rand=lasso_cv.score(X_test, y_test.sample(frac = 1).values)\n",
    "\n",
    "            if model==\"Ridge\":\n",
    "    #             scores,scores_rand=lasso_cv_plus_model_selection(cp[cp_features],l1k[l],k_fold,group_labels)        \n",
    "    # #                 scores,scores_rand=lasso_cv(cp[cp_features],l1k[l],k_fold,group_labels)\n",
    "                alphas = np.linspace(0.1, 0.2, 20)\n",
    "            #     alphas = np.logspace(-4, -0.5, 30)\n",
    "                ridge_cv = linear_model.RidgeCV(alphas=alphas)\n",
    "\n",
    "                ridge_cv.fit(X_train, y_train)  \n",
    "                r2_score=ridge_cv.score(X_test, y_test.values) \n",
    "                r2_rand=ridge_cv.score(X_test, y_test.sample(frac = 1).values)\n",
    "                \n",
    "            elif model==\"MLP\":\n",
    "#                 scores,scores_rand=MLP_cv_plus_model_selection(cp[cp_features],l1k[l],k_fold,group_labels)\n",
    "    #                 scores,scores_rand=MLP_cv(cp[cp_features],l1k[l],k_fold,group_labels)  \n",
    "                mlp_gs = MLPRegressor(activation='logistic',max_iter=500)\n",
    "                parameter_space = {\n",
    "                    'hidden_layer_sizes': [(50,),(10,30,10),(50,10),(50,10,10)],\n",
    "                    'alpha': [0.0001, 0.05,0.01,0.2],\n",
    "                    'early_stopping':[True,False]\n",
    "                }\n",
    "\n",
    "                clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=-1, cv=2)\n",
    "                clf.fit(X_train, y_train)  \n",
    "                r2_score=clf.score(X_test, y_test.values)    \n",
    "                r2_rand=clf.score(X_test, y_test.sample(frac = 1).values)\n",
    "    \n",
    "            pred_df.loc[n,l]=r2_score\n",
    "            pred_df_rand.loc[n,l]=r2_rand\n",
    "\n",
    "    \n",
    "########################### mapping prob_ids to genes names    \n",
    "meta=pd.read_csv(\"/home/ubuntu/bucket/projects/2018_04_20_Rosetta/workspace/metadata/affy_probe_gene_mapping.txt\",delimiter=\"\\t\",header=None, names=[\"probe_id\", \"gene\"])\n",
    "meta_gene_probID=meta.set_index('probe_id')\n",
    "d = dict(zip(meta_gene_probID.index, meta_gene_probID['gene']))\n",
    "pred_df = pred_df.rename(columns=d)    \n",
    "pred_df_rand = pred_df_rand.rename(columns=d)  \n",
    "\n",
    "pred_df.loc[0,'DT']='LUAD-LINCS'\n",
    "pred_df.loc[1,'DT']='LINCS-LUAD'\n",
    "\n",
    "pred_df_rand.loc[0,'DT']='LUAD-LINCS'\n",
    "pred_df_rand.loc[1,'DT']='LINCS-LUAD'\n",
    "\n",
    "meltedPredDF=pd.melt(pred_df,id_vars='DT').rename(columns={'variable':'lmGens','value':'pred score'})\n",
    "meltedPredDF_rand=pd.melt(pred_df_rand,id_vars='DT').rename(columns={'variable':'lmGens','value':'pred score'})\n",
    "meltedPredDF['d']=\"n-folds\"\n",
    "meltedPredDF_rand['d']=\"random\"\n",
    "\n",
    "filename=results_dir+'/SingleGenePred/scores_cross_dts.xlsx'\n",
    "\n",
    "profTypeAbbrev=''.join([s[0] for s in profileType.split('_')])\n",
    "\n",
    "saveAsNewSheetToExistingFile(filename,pd.concat([meltedPredDF,meltedPredDF_rand],ignore_index=True),\\\n",
    "                             model+'-'+profTypeAbbrev+'-'+f+'-ht')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CD58</th>\n",
       "      <th>HMGCR</th>\n",
       "      <th>BLMH</th>\n",
       "      <th>CLTB</th>\n",
       "      <th>KIF14</th>\n",
       "      <th>MMP1</th>\n",
       "      <th>PRKCD</th>\n",
       "      <th>EDEM1</th>\n",
       "      <th>LAGE3</th>\n",
       "      <th>FZD1</th>\n",
       "      <th>...</th>\n",
       "      <th>CRTAP</th>\n",
       "      <th>SPAG7</th>\n",
       "      <th>RPA3</th>\n",
       "      <th>PDLIM1</th>\n",
       "      <th>EPB41L2</th>\n",
       "      <th>H2AFV</th>\n",
       "      <th>GADD45B</th>\n",
       "      <th>PRR7</th>\n",
       "      <th>WFS1</th>\n",
       "      <th>DT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-10.055338</td>\n",
       "      <td>-5.012601</td>\n",
       "      <td>-4.766265</td>\n",
       "      <td>-4.301978</td>\n",
       "      <td>-9.485024</td>\n",
       "      <td>-1.83599</td>\n",
       "      <td>-27.528061</td>\n",
       "      <td>-39.917412</td>\n",
       "      <td>-18.191523</td>\n",
       "      <td>-9.248155</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.547668</td>\n",
       "      <td>-22.937341</td>\n",
       "      <td>-13.677729</td>\n",
       "      <td>-8.230724</td>\n",
       "      <td>-6.657306</td>\n",
       "      <td>-24.429953</td>\n",
       "      <td>-14.383658</td>\n",
       "      <td>-7.766039</td>\n",
       "      <td>-6.773811</td>\n",
       "      <td>LUAD-LINCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-123.699955</td>\n",
       "      <td>-25.270125</td>\n",
       "      <td>-15.400285</td>\n",
       "      <td>-16.318289</td>\n",
       "      <td>-22.064298</td>\n",
       "      <td>-46.247488</td>\n",
       "      <td>-9.318376</td>\n",
       "      <td>-13.648549</td>\n",
       "      <td>-46.4902</td>\n",
       "      <td>-22.233232</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.444562</td>\n",
       "      <td>-59.813391</td>\n",
       "      <td>-6.74915</td>\n",
       "      <td>-45.762048</td>\n",
       "      <td>-21.068022</td>\n",
       "      <td>-18.150162</td>\n",
       "      <td>-16.763179</td>\n",
       "      <td>-55.184038</td>\n",
       "      <td>-28.33788</td>\n",
       "      <td>LINCS-LUAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 979 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CD58      HMGCR       BLMH       CLTB      KIF14       MMP1  \\\n",
       "0  -10.055338  -5.012601  -4.766265  -4.301978  -9.485024   -1.83599   \n",
       "1 -123.699955 -25.270125 -15.400285 -16.318289 -22.064298 -46.247488   \n",
       "\n",
       "       PRKCD      EDEM1      LAGE3       FZD1  ...      CRTAP      SPAG7  \\\n",
       "0 -27.528061 -39.917412 -18.191523  -9.248155  ... -24.547668 -22.937341   \n",
       "1  -9.318376 -13.648549   -46.4902 -22.233232  ... -31.444562 -59.813391   \n",
       "\n",
       "        RPA3     PDLIM1    EPB41L2      H2AFV    GADD45B       PRR7      WFS1  \\\n",
       "0 -13.677729  -8.230724  -6.657306 -24.429953 -14.383658  -7.766039 -6.773811   \n",
       "1   -6.74915 -45.762048 -21.068022 -18.150162 -16.763179 -55.184038 -28.33788   \n",
       "\n",
       "           DT  \n",
       "0  LUAD-LINCS  \n",
       "1  LINCS-LUAD  \n",
       "\n",
       "[2 rows x 979 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso-n-filt-ht  saved!\n"
     ]
    }
   ],
   "source": [
    "filename=results_dir+'/SingleGenePred/scores_cross_dts.xlsx'\n",
    "\n",
    "profTypeAbbrev=''.join([s[0] for s in profileType.split('_')])\n",
    "\n",
    "saveAsNewSheetToExistingFile(filename,pd.concat([meltedPredDF],ignore_index=True),\\\n",
    "                             model+'-'+profTypeAbbrev+'-'+f+'-ht')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave dataset out Cross validation - on CDRP-bio and LINCS (2-folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/workspace_rosetta/workspace/software/2021_Haghighi_NeurIPS_Dataset_submitted/utils/readProfiles.py:21: DtypeWarning: Columns (18,19,1820,1821) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  cp_data_repLevel=pd.read_csv(dataDir+'/CellPainting/replicate_level_cp_'+profileType+'.csv.gz')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINCS: Replicate Level Shapes (nSamples x nFeatures): cp:  52223 , 1670 ,  l1k:  27837 , 978\n",
      "l1k n of rep:  3.0\n",
      "cp n of rep:  5.0\n",
      "CP: from  9394  to  4647\n",
      "l1k: from  8369  to  2338\n",
      "CP and l1k high rep overlap:  1140\n",
      "Treatment Level Shapes (nSamples x nFeatures+metadata): (1141, 1673) (1141, 980) Merged Profiles Shape: (1141, 2652)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/workspace_rosetta/workspace/software/2021_Haghighi_NeurIPS_Dataset_submitted/utils/readProfiles.py:22: DtypeWarning: Columns (981,982,983) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  l1k_data_repLevel=pd.read_csv(dataDir+'/L1000/replicate_level_l1k.csv.gz')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDRP-bio: Replicate Level Shapes (nSamples x nFeatures): cp:  21122 , 1570 ,  l1k:  6929 , 977\n",
      "l1k n of rep:  2.0\n",
      "cp n of rep:  8.0\n",
      "CP: from  2239  to  312\n",
      "l1k: from  1535  to  448\n",
      "CP and l1k high rep overlap:  131\n",
      "Treatment Level Shapes (nSamples x nFeatures+metadata): (132, 1573) (132, 981) Merged Profiles Shape: (132, 2553)\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "# dataset options: 'CDRP' , 'LUAD', 'TAORF', 'LINCS', 'CDRP-bio'\n",
    "datasets=['CDRP-bio','LINCS'];\n",
    "# datasets=['LINCS', 'CDRP-bio','CDRP'];\n",
    "\n",
    "################################################\n",
    "# CP Profile Type options: 'augmented' , 'normalized', 'normalized_variable_selected'\n",
    "profileType='normalized'\n",
    "\n",
    "################################################\n",
    "# filtering to compounds which have high replicates for both GE and CP datasets\n",
    "# highRepOverlapEnabled=0\n",
    "# 'highRepUnion','highRepOverlap'\n",
    "filter_perts='highRepOverlap'\n",
    "\n",
    "################################################\n",
    "pertColName='PERT'\n",
    "profileLevel='treatment'; #'replicate'  or  'treatment'\n",
    "if filter_perts:\n",
    "    f='filt'\n",
    "else:\n",
    "    f=''\n",
    "    \n",
    "mergProf_treatLevel_LI,cp_features_LI,l1k_features_LI= \\\n",
    "read_paired_treatment_level_profiles(procProf_dir,'LINCS',profileType,filter_perts,1)\n",
    "\n",
    "mergProf_treatLevel_LU,cp_features_LU,l1k_features_LU=\\\n",
    "read_paired_treatment_level_profiles(procProf_dir,'CDRP-bio',profileType,filter_perts,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_features_unionFs=list(set(cp_features_LU).union(set(cp_features_LI)))\n",
    "l1k_features_unionFs=list(set(l1k_features_LU).union(set(l1k_features_LI)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# cp_features=list(set(cp_features_LU) & set(cp_features_LI))\n",
    "# l1k_features=list(set(l1k_features_LU) & set(l1k_features_LI))\n",
    "# profileType='normalized'\n",
    "\n",
    "cp_features=list(set(cp_features_LU) & set(cp_features_LI) & set(cp_features_unionFs))\n",
    "l1k_features=list(set(l1k_features_LU) & set(l1k_features_LI)& set(l1k_features_unionFs))\n",
    "profileType='normalized_variable_selected_union'\n",
    "\n",
    "\n",
    "####################\n",
    "l1k_LU=mergProf_treatLevel_LU[[pertColName]+l1k_features]\n",
    "cp_LU=mergProf_treatLevel_LU[[pertColName]+cp_features]\n",
    "\n",
    "l1k_LI=mergProf_treatLevel_LI[[pertColName]+l1k_features]\n",
    "cp_LI=mergProf_treatLevel_LI[[pertColName]+cp_features]\n",
    "\n",
    "####################\n",
    "\n",
    "\n",
    "l1k_scaled_LU=l1k_LU.copy();l1k_scaled_LI=l1k_LI.copy()\n",
    "l1k_scaled_LU[l1k_features] = preprocessing.StandardScaler().fit_transform(l1k_LU[l1k_features].values)\n",
    "l1k_scaled_LI[l1k_features] = preprocessing.StandardScaler().fit_transform(l1k_LI[l1k_features].values)\n",
    "\n",
    "cp_scaled_LU=cp_LU.copy();cp_scaled_LI=cp_LI.copy()\n",
    "cp_scaled_LU[cp_features] = preprocessing.StandardScaler().fit_transform(cp_LU[cp_features].values.astype('float64'))\n",
    "cp_scaled_LI[cp_features] = preprocessing.StandardScaler().fit_transform(cp_LI[cp_features].values.astype('float64'))\n",
    "\n",
    "fold1=[[cp_scaled_LU,l1k_scaled_LU],[cp_scaled_LI,l1k_scaled_LI]]\n",
    "fold2=[[cp_scaled_LI,l1k_scaled_LI],[cp_scaled_LU,l1k_scaled_LU]]\n",
    "\n",
    "\n",
    "pred_df=pd.DataFrame(index=range(2),columns=l1k_features)\n",
    "pred_df_rand=pd.DataFrame(index=range(2),columns=l1k_features)\n",
    "\n",
    "# for dt in [fold1,fold2]:\n",
    "for n,dt in zip([0,1],[fold1,fold2]):\n",
    "    \n",
    "    for model in [\"Lasso\"]:#[\"Lasso\",\"MLP\",\"Ridge\"]:    \n",
    "\n",
    "        ##############################\n",
    "        ii=0\n",
    "        for l in l1k_features:\n",
    "            ii+=1\n",
    "            print(ii)\n",
    "\n",
    "            X_train, X_test = dt[0][0][cp_features].values, dt[1][0][cp_features].values\n",
    "            y_train, y_test = dt[0][1][l].values, dt[1][1][l]#.values\n",
    "\n",
    "            if model==\"Lasso\":\n",
    "    #             scores,scores_rand=lasso_cv_plus_model_selection(cp[cp_features],l1k[l],k_fold,group_labels)        \n",
    "    # #                 scores,scores_rand=lasso_cv(cp[cp_features],l1k[l],k_fold,group_labels)\n",
    "                alphas1 = np.linspace(0, 0.2, 20)\n",
    "                alphas2 = np.linspace(0.2, 0.5, 10)[1:]\n",
    "                alphas=np.concatenate((alphas1,alphas2))\n",
    "            #     alphas = np.logspace(-4, -0.5, 30)\n",
    "                lasso_cv = linear_model.LassoCV(alphas=alphas, random_state=0, max_iter=1000,selection='random')\n",
    "\n",
    "                lasso_cv.fit(X_train, y_train)  \n",
    "                r2_score=lasso_cv.score(X_test, y_test.values) \n",
    "                r2_rand=lasso_cv.score(X_test, y_test.sample(frac = 1).values)\n",
    "\n",
    "            if model==\"Ridge\":\n",
    "    #             scores,scores_rand=lasso_cv_plus_model_selection(cp[cp_features],l1k[l],k_fold,group_labels)        \n",
    "    # #                 scores,scores_rand=lasso_cv(cp[cp_features],l1k[l],k_fold,group_labels)\n",
    "                alphas = np.linspace(0.1, 0.2, 20)\n",
    "            #     alphas = np.logspace(-4, -0.5, 30)\n",
    "                ridge_cv = linear_model.RidgeCV(alphas=alphas)\n",
    "\n",
    "                ridge_cv.fit(X_train, y_train)  \n",
    "                r2_score=ridge_cv.score(X_test, y_test.values) \n",
    "                r2_rand=ridge_cv.score(X_test, y_test.sample(frac = 1).values)\n",
    "                \n",
    "            elif model==\"MLP\":\n",
    "#                 scores,scores_rand=MLP_cv_plus_model_selection(cp[cp_features],l1k[l],k_fold,group_labels)\n",
    "    #                 scores,scores_rand=MLP_cv(cp[cp_features],l1k[l],k_fold,group_labels)  \n",
    "                mlp_gs = MLPRegressor(activation='logistic',max_iter=500)\n",
    "                parameter_space = {\n",
    "                    'hidden_layer_sizes': [(50,),(10,30,10),(50,10),(50,10,10)],\n",
    "                    'alpha': [0.0001, 0.05,0.01,0.2],\n",
    "                    'early_stopping':[True,False]\n",
    "                }\n",
    "\n",
    "                clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=-1, cv=2)\n",
    "                clf.fit(X_train, y_train)  \n",
    "                r2_score=clf.score(X_test, y_test.values)    \n",
    "                r2_rand=clf.score(X_test, y_test.sample(frac = 1).values)\n",
    "    \n",
    "            pred_df.loc[n,l]=r2_score\n",
    "            pred_df_rand.loc[n,l]=r2_rand\n",
    "\n",
    "    \n",
    "########################### mapping prob_ids to genes names    \n",
    "meta=pd.read_csv(\"/home/ubuntu/bucket/projects/2018_04_20_Rosetta/workspace/metadata/affy_probe_gene_mapping.txt\",delimiter=\"\\t\",header=None, names=[\"probe_id\", \"gene\"])\n",
    "meta_gene_probID=meta.set_index('probe_id')\n",
    "d = dict(zip(meta_gene_probID.index, meta_gene_probID['gene']))\n",
    "pred_df = pred_df.rename(columns=d)    \n",
    "pred_df_rand = pred_df_rand.rename(columns=d)  \n",
    "\n",
    "pred_df.loc[0,'DT']='CDRPbio-LINCS'\n",
    "pred_df.loc[1,'DT']='LINCS-CDRPbio'\n",
    "\n",
    "pred_df_rand.loc[0,'DT']='CDRPbio-LINCS'\n",
    "pred_df_rand.loc[1,'DT']='LINCS-CDRPbio'\n",
    "\n",
    "meltedPredDF=pd.melt(pred_df,id_vars='DT').rename(columns={'variable':'lmGens','value':'pred score'})\n",
    "meltedPredDF_rand=pd.melt(pred_df_rand,id_vars='DT').rename(columns={'variable':'lmGens','value':'pred score'})\n",
    "meltedPredDF['d']=\"n-folds\"\n",
    "meltedPredDF_rand['d']=\"random\"\n",
    "\n",
    "filename=results_dir+'/SingleGenePred/scores_cross_dts_CD_LI.xlsx'\n",
    "\n",
    "profTypeAbbrev=''.join([s[0] for s in profileType.split('_')])\n",
    "\n",
    "saveAsNewSheetToExistingFile(filename,pd.concat([meltedPredDF,meltedPredDF_rand],ignore_index=True),\\\n",
    "                             model+'-'+profTypeAbbrev+'-'+f+'-ht')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lasso-nvsu-filt-ht'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model+'-'+profTypeAbbrev+'-'+f+'-ht'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mergProf_treatLevel_LI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmergProf_treatLevel_LI\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mergProf_treatLevel_LI' is not defined"
     ]
    }
   ],
   "source": [
    "mergProf_treatLevel_LI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "438.212px",
    "left": "1507.78px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
